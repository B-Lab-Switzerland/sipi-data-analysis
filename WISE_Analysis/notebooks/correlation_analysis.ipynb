{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a85fd5-9650-4b73-bb13-01f78c7241dc",
   "metadata": {},
   "source": [
    "# Country-level Analysis of beyond-GDP Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea5262-ddc8-4331-8ebd-fd274a9c63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stdlib imports\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "from typing import Dict, List\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# 3rd party imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e36517-ef60-43b6-a5d8-d7816fb19690",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f142ea-3aae-4361-a87a-67069e84a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "data_root = Path(\"../../data\")\n",
    "wisedb_path = data_root / \"WISE_Database/Data/WISE_Database/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34073992-26ec-4cc7-b43c-c459e0492b57",
   "metadata": {},
   "source": [
    "## WISE data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c8751-653a-4525-a5bd-b715afafc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_WISE_to_disk(storage_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Downloads the WISE data to disk.\n",
    "\n",
    "    The WISE database is downloaded as a ZIP file,\n",
    "    which is written to disk and extracted into a\n",
    "    folder.\n",
    "    \"\"\"\n",
    "    # Download ZIP file\n",
    "    download_url = \"https://springernature.figshare.com/ndownloader/files/49085821/WISE_Database.zip\"\n",
    "    r = requests.get(download_url, stream=True)\n",
    "\n",
    "    # Write ZIP file to disk\n",
    "    write_path = storage_path / \"WISE_Database.zip\"\n",
    "    with open(write_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)\n",
    "\n",
    "    # Extract ZIP file\n",
    "    with zipfile.ZipFile(write_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c3388-3e01-4ec7-a0b6-6249ecaa4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (wisedb_path / \"WISE_Database.xlsx\").exists():\n",
    "    print(\"File not yet available --> Downloading...\")\n",
    "    download_WISE_to_disk(data_root)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Data already available. No download required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183ea2e-0087-4b48-a5f7-42486043ac9d",
   "metadata": {},
   "source": [
    "## WISE data analysis with Focus on Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6a367-5744-40df-af32-972bbe3862eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the WISE database into memory\n",
    "wise_db = dict()\n",
    "\n",
    "for sheet in [\"Metrics Info\", \"C Data\"]: # The sheets \"Content\", \"CG Data\", \"Metrics C&CG\", \"C&CG Code\" are not needed.\n",
    "    wise_db[sheet] = pd.read_excel(wisedb_path / \"WISE_Database.xlsx\", sheet_name=sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cd401-01df-47ee-9739-700bb6c078b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for Switzerland (ISO3 = \"CHE\")\n",
    "wise_ch = wise_db[\"C Data\"].loc[wise_db[\"C Data\"][\"ISO3\"].values == \"CHE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f3236-2a03-4b13-bbc5-84fd0952fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into dictionary of dataframes. Each key-value pair belongs to a specific indicator\n",
    "wise_ch_ind__raw = dict()\n",
    "\n",
    "for acr in wise_ch[\"Acronym\"].unique():\n",
    "    wise_ch_ind__raw[acr] = wise_ch.loc[wise_ch[\"Acronym\"]==acr]\n",
    "\n",
    "# Current number of indicators\n",
    "len(wise_ch_ind__raw.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed0012-1270-4519-b123-db12f124fed5",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b132ba4-937f-442e-8240-bf604b07ba51",
   "metadata": {},
   "source": [
    "#### Step 1: Ignore indices that have not been recorded for at least 10 years (i.e. 10 data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ce1cb-209e-4b0b-b0d3-b119391a5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "wise_ch_ind__statrel = ({k: v for (k,v) in wise_ch_ind__raw.items() if len(v[\"Year\"])>=10})\n",
    "\n",
    "# Current number of indicators\n",
    "len(wise_ch_ind__statrel.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9b3c9-a0c5-4b52-99f0-76a83f6d5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed indicators\n",
    "set(wise_ch_ind__raw.keys()) - set(wise_ch_ind__statrel.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd4574-c09e-484a-9417-b3268b489065",
   "metadata": {},
   "source": [
    "#### Step 2: Ignore constant indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858a805-4ae0-4980-9039-84951e787e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wise_ch_ind__nonconst = ({k: v for (k,v) in wise_ch_ind__statrel.items() if v[\"Value\"].std()>0})\n",
    "\n",
    "# Current number of indicators\n",
    "len(wise_ch_ind__nonconst.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9cfd4-e6c2-4f36-b3df-99859d211dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed indicators\n",
    "set(wise_ch_ind__statrel.keys() - set(wise_ch_ind__nonconst.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71855dfc-ede7-4ab5-b9c1-bb0c895bf86e",
   "metadata": {},
   "source": [
    "#### Step 3: Split by capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6055e-e0ba-458c-a7ca-ae3c52abbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_capitals = [\"Human\", \"Social\", \"Natural\", \"Economic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d35c5-d8c3-4939-b896-6ec4e437b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping from WISE categories to four capitals:\n",
    "# Wellbeing -> Human\n",
    "# Inclusion -> Social\n",
    "# Sustainability -> Natural\n",
    "# Economy and Society -> Economic\n",
    "capital_map = {\"Human\": list(wise_db[\"Metrics Info\"].loc[wise_db[\"Metrics Info\"][\"Wellbeing\"] == \"X\", \"Acronym\"].values),\n",
    "               \"Social\": list(wise_db[\"Metrics Info\"].loc[wise_db[\"Metrics Info\"][\"Inclusion\"] == \"X\", \"Acronym\"].values),\n",
    "               \"Natural\": list(wise_db[\"Metrics Info\"].loc[wise_db[\"Metrics Info\"][\"Sustainability\"] == \"X\", \"Acronym\"].values),\n",
    "               \"Economic\": list(wise_db[\"Metrics Info\"].loc[wise_db[\"Metrics Info\"][\"Economy and Society\"] == \"X\", \"Acronym\"].values)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a676e3-6da7-40b8-970d-2372cffc0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with a key-value pair for each capital\n",
    "wise_capitals_ch = dict()\n",
    "\n",
    "for cap in four_capitals:\n",
    "    cap_dict = {k: v for (k,v) in wise_ch_ind__nonconst.items() if k in capital_map[cap]}\n",
    "    wise_capitals_ch[cap] = pd.concat(cap_dict, ignore_index=True)\\\n",
    "                              .pivot(index=\"Acronym\", columns=\"Year\", values=\"Value\")\\\n",
    "                              .astype(float)\n",
    "    wise_capitals_ch[cap].columns.astype(int)\n",
    "    wise_capitals_ch[cap] = wise_capitals_ch[cap][sorted(wise_capitals_ch[cap].columns)]\n",
    "\n",
    "    # Fix time axis: Include every year between minimal and maximal year\n",
    "    min_year = wise_capitals_ch[cap].columns.min()\n",
    "    max_year = wise_capitals_ch[cap].columns.max()\n",
    "    full_years = list(range(min_year, max_year + 1))\n",
    "\n",
    "    # Reindex columns to include every year (adds NaNs where data is missing)\n",
    "    wise_capitals_ch[cap] = wise_capitals_ch[cap].reindex(columns=full_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965aa76-8f4b-457a-b2d1-dd3d31ba057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cap in four_capitals:\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    sns.heatmap(wise_capitals_ch[cap].isnull(), \n",
    "                cbar=False,        # Hide color bar\n",
    "                cmap=['black', 'white'],  # black = not null, white = null\n",
    "                xticklabels = True,\n",
    "                yticklabels = True,\n",
    "                ax=ax)\n",
    "    \n",
    "    ax.grid(True)\n",
    "\n",
    "    # Set axis ticks (for x axis: plot only decades)\n",
    "    tick_locs = [i for i, year in enumerate(wise_capitals_ch[cap].columns) if year % 10 == 0]\n",
    "    tick_labels = [str(year) for year in wise_capitals_ch[cap].columns if year % 10 == 0]\n",
    "    \n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_xticklabels(tick_labels, rotation=45, fontsize=8)\n",
    "    \n",
    "    ax.set_yticks(range(len(wise_capitals_ch[cap].index)))\n",
    "    ax.set_yticklabels(wise_capitals_ch[cap].index, fontsize=5)\n",
    "\n",
    "    # Add axis lables\n",
    "    ax.set_xlabel(\"Years\")\n",
    "    ax.set_ylabel(\"Indeces\")\n",
    "\n",
    "    # Add title\n",
    "    ax.set_title(cap + \" Capital\")\n",
    "    #fig.savefig(\"./valueAvailabilityMap_\" + cap + \"Capital.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2546cc4-d65a-405b-9240-5ad8c94561cb",
   "metadata": {},
   "source": [
    "Looking at these graphics it becomes evident that the data availability is quite good after starting in the year 1995. For this reason, I shall interpolate metrics wherever possible in order to maximize the data availability between 1995 and 2025. Then, this is the time window I focus on in the subsequent analysis.\n",
    "\n",
    "Obviously, this strategy ignores a number of metrics. In the future, one could think of finding other time windows where ignored metrics could be correlated with metrics that have been taken into account in order to get a sense of whether those metrics contain relevant information content or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef61f2-8eb5-4bd8-b52e-00ff716767a2",
   "metadata": {},
   "source": [
    "#### Step 4: Removing metrics with insufficient availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175e39f-6a09-476f-90ed-81778a4f92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove indicators with no data whatsoever prior to 1995\n",
    "wise_capitals_ch_reduced = dict()\n",
    "\n",
    "for cap in four_capitals:\n",
    "    wise_capitals_ch_reduced[cap] = wise_capitals_ch[cap].copy()\n",
    "    tmp = wise_capitals_ch_reduced[cap].loc[:,wise_capitals_ch_reduced[cap].columns < 1995].dropna(axis=\"rows\", how=\"all\")\n",
    "    wise_capitals_ch_reduced[cap] = wise_capitals_ch[cap].loc[wise_capitals_ch[cap].index.isin(tmp.index),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842497f-a4c1-4289-89d0-271ee299785b",
   "metadata": {},
   "source": [
    "#### Step 5: Interpolation of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80759250-6947-4f7c-ab86-0ddb2d5b4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data between 1995 and 2025\n",
    "wise_capitals_ch_interp = dict()\n",
    "\n",
    "for cap in four_capitals:\n",
    "    wise_capitals_ch_interp[cap] = wise_capitals_ch_reduced[cap]\\\n",
    "                                        .astype(float)\\\n",
    "                                        .interpolate(\"linear\",axis=\"columns\", limit_area=\"inside\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    sns.heatmap(wise_capitals_ch_interp[cap].isnull(), \n",
    "                cbar=False,        # Hide color bar\n",
    "                cmap=['black', 'white'],  # black = not null, white = null\n",
    "                yticklabels=True,\n",
    "                ax=ax)\n",
    "    \n",
    "    ax.grid(True)\n",
    "\n",
    "    tick_locs = [i for i, year in enumerate(wise_capitals_ch_interp[cap].columns) if year % 10 == 0]\n",
    "    tick_labels = [str(year) for year in wise_capitals_ch_interp[cap].columns if year % 10 == 0]\n",
    "    \n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_xticklabels(tick_labels, rotation=45, fontsize=8)\n",
    "    \n",
    "    ax.set_yticklabels(wise_capitals_ch_interp[cap].index,fontsize=5)\n",
    "    ax.set_xlabel(\"Years\")\n",
    "    ax.set_ylabel(\"Indeces\")\n",
    "    ax.set_title(cap + \" Capital\")\n",
    "    #fig.savefig(\"./valueAvailabilityMap_\" + cap + \"Capital__afterInterpolation.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b8f85-d80d-4c68-a93b-79ee5f6252c6",
   "metadata": {},
   "source": [
    "#### Step 6: Remove Metrics That are missing values between 1995 and 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9520eaf-07e9-41bf-9e0a-1377e06df543",
   "metadata": {},
   "outputs": [],
   "source": [
    "wise_capitals_ch_clean = dict()\n",
    "\n",
    "for cap in four_capitals:\n",
    "    time_window = [a and b for (a,b) in zip(wise_capitals_ch_interp[cap].columns>=1995, \n",
    "                                            wise_capitals_ch_interp[cap].columns<=2020)\n",
    "                  ]\n",
    "    wise_capitals_ch_clean[cap] = wise_capitals_ch_interp[cap].loc[:, time_window].dropna(axis=\"rows\", how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4732b-81e8-4584-b21c-fbd04b5c862a",
   "metadata": {},
   "source": [
    "### Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e2d72-f608-4e7c-bddb-20e5e740bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are there any NULL values left?\")\n",
    "for cap in four_capitals:\n",
    "    print(f\"{cap}: {wise_capitals_ch_clean[cap].isnull().any().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28396011-980c-425b-b202-7277e75c40ab",
   "metadata": {},
   "source": [
    "#### Step 7: Ignore again constant indices (if present)\n",
    "Notice: In the next step we also transpose the matrices such that the various indicators and indices (features) are stored in the columns while the different years (i.e. different observations) are stored in rows as is customary in machine learning community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fae9d-b9fb-4e40-8793-6c6f15f59dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cap in four_capitals:\n",
    "    df = wise_capitals_ch_clean[cap].transpose()\n",
    "    wise_capitals_ch_clean[cap] = df.loc[:, (df != df.iloc[0]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb2c0d-0747-4cd2-b832-8084deb235c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Count number of remaining metrics\n",
    "n_metrics = 0\n",
    "for cap in four_capitals:\n",
    "    n_metrics += wise_capitals_ch_clean[cap].shape[0]\n",
    "\n",
    "n_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc9f44-1693-4bfd-a6c1-419be05bde59",
   "metadata": {},
   "source": [
    "### Create a list of the remaining indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba35d5-cff3-47da-8321-d7c044b35484",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_indices = [idx_name_map[idx] for idx in wise_capitals_ch_clean[\"Human\"].columns]\n",
    "social_indices = [idx_name_map[idx] for idx in wise_capitals_ch_clean[\"Social\"].columns]\n",
    "natural_indices = [idx_name_map[idx] for idx in wise_capitals_ch_clean[\"Natural\"].columns]\n",
    "economic_indices = [idx_name_map[idx] for idx in wise_capitals_ch_clean[\"Economic\"].columns]\n",
    "\n",
    "# Combining all capitals together and drop duplicates\n",
    "all_indices = list(set(human_indices + social_indices + natural_indices + economic_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6903562-9d56-4b1a-8d21-2edbdc9526cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42378631-9901-4b8e-b9ec-68db55bb4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save list of indicators to file\n",
    "pd.Series(all_indices, name=\"Indices\").to_csv(\"./ch_indices_between_1995_and_2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6977d4-a78e-4e47-8b33-7f2fc603ec87",
   "metadata": {},
   "source": [
    "## Correlation analysis within Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5651f1d-2b86-4321-abbb-15238303a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationAnalysis(object):\n",
    "    def __init__(self, data: dict[str, pd.DataFrame], name_map=None, timeseries=True):\n",
    "        self.data = data\n",
    "        self.classes = self.data.keys()\n",
    "        self.is_timeseries = timeseries\n",
    "        self.name_map = name_map\n",
    "    \n",
    "    def compute_correlation(self):\n",
    "        self.corrmats = dict()\n",
    "        for cl in self.classes:\n",
    "            if self.is_timeseries:\n",
    "                # use pct_change method to detrend the timeseries\n",
    "                self.corrmats[cl] = self.data[cl].pct_change().corr()\n",
    "            else:\n",
    "                self.corrmats[cl] = self.data[cl].corr()\n",
    "\n",
    "    def plot_corr_heatmap(self, title_root: str, use_name_map: bool = False, mask: Dict[\"str\", List[\"str\"]] = None):\n",
    "        for cl in self.classes:\n",
    "            df = self.corrmats[cl]\n",
    "            if mask:\n",
    "                assert mask.keys() == self.classes\n",
    "                df = df.loc[mask[cl], mask[cl]]\n",
    "            \n",
    "            if use_name_map:\n",
    "                df = df.rename(idx_name_map, axis=1).rename(idx_name_map, axis=0)\n",
    "                \n",
    "            fig, ax = plt.subplots(figsize=(10,9))    \n",
    "            sns.heatmap(df, vmin=-1, vmax=1, ax=ax)\n",
    "            ax.set_title(cap + \" Capital\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            fig_title = \"./\" + title_root + \"_\" + cl + \"Capital\"\n",
    "            if self.is_timeseries:\n",
    "                fig_title += \"_detrended\"\n",
    "                \n",
    "            #fig.savefig(fig_title + \".pdf\")\n",
    "\n",
    "    def drop_strong_correlations(self, threshold: float):\n",
    "        \"\"\"\n",
    "        Filter which indices to keep and which ones to drop\n",
    "        \"\"\"\n",
    "        keepers = dict()\n",
    "        droppers = dict()\n",
    "        \n",
    "        for cl in self.classes:\n",
    "            indices = self.corrmats[cl].index\n",
    "            keepers[cl] = []\n",
    "            droppers[cl] = []\n",
    "            for (i1, i2) in combinations(indices,2):\n",
    "                keepers[cl].append(i1)\n",
    "                if np.abs(self.corrmats[cl].loc[i1,i2])>threshold:\n",
    "                    droppers[cl].append(i2)\n",
    "        \n",
    "            droppers[cl] = set(droppers[cl])\n",
    "            keepers[cl] = list(set(keepers[cl]) - droppers[cl])\n",
    "\n",
    "        return keepers\n",
    "\n",
    "    df_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38b6fb-5062-4216-a997-0d0c1c2bdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_name_map = {k: v for [k,v] in wise_db[\"Metrics Info\"][[\"Acronym\", \"Metric Full Name\"]].to_dict(orient=\"tight\")[\"data\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd083d-1ba5-44d9-a278-5fac99c12ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ca = CorrelationAnalysis(wise_capitals_ch_clean, name_map = idx_name_map)\n",
    "ca.compute_correlation()\n",
    "ca.plot_corr_heatmap(title_root=\"corrMat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77aa32d-f377-462c-8bdb-f7640510e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_thrsh = [i/10 for i in range(3,11)]\n",
    "len_keepers = []\n",
    "for thr in corr_thrsh:\n",
    "    keepers = ca.drop_strong_correlations(thr)\n",
    "    len_keepers.append(len(set([elm for sl in [l for k, l in keepers.items()] for elm in sl])))\n",
    "\n",
    "# Compute maximum for normalization\n",
    "max_count = max(len_keepers)\n",
    "fractions = [count / max_count for count in len_keepers]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(len(corr_thrsh)),height=fractions)\n",
    "ax.grid(True)\n",
    "\n",
    "ax.set_xticks(range(len(corr_thrsh)))\n",
    "ax.set_xticklabels(corr_thrsh)\n",
    "ax.set_xlabel(r\"upper correlation threshold $\\theta_{max}$\")\n",
    "\n",
    "ax.set_yticks([i/10 for i in range(11)])\n",
    "ax.set_yticklabels([i/10 for i in range(11)])\n",
    "ax.set_ylabel(\"fraction of retained indicators\")\n",
    "\n",
    "ax.set_title(r\"Number of retained indicators after removing those with correlations > $\\theta_{max}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a072e-61bd-43e2-b75d-6156e73cdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepers = ca.drop_strong_correlations(0.9)\n",
    "ca.plot_corr_heatmap(title_root=\"RelevantIndicators_corrMatrix\", use_name_map = True, mask=keepers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3386ac-defe-41d2-9ad1-3ac16a7260bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of remaining indicators per capital:\")\n",
    "for cap in four_capitals:\n",
    "    print(cap + \":\", len(keepers[cap]))\n",
    "print()\n",
    "print(\"Total number of remaining indicators (excluding duplicates):\", len(set([elm for sl in [l for k, l in keepers.items()] for elm in sl])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf473b-e13e-4078-b8a6-236bf2a36e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = dict()\n",
    "for cap in four_capitals:\n",
    "    for idx in keepers[cap]:\n",
    "        corr_series = ca.corrmats[cap][idx]\n",
    "        strong_corr = corr_series[np.abs(corr_series)>0.9]\n",
    "        \n",
    "        if len(strong_corr)==1:\n",
    "            continue\n",
    "        tmp = strong_corr.to_frame()\\\n",
    "            .reset_index()\\\n",
    "            .rename({\"index\": \"Acronym\"}, axis=1)\\\n",
    "            .merge(wise_db[\"Metrics Info\"][[\"Acronym\", \"Metric Full Name\"]], \n",
    "                   on=\"Acronym\", \n",
    "                   how=\"inner\"\n",
    "                  )\n",
    "        \n",
    "        current_full_name = wise_db[\"Metrics Info\"].loc[wise_db[\"Metrics Info\"][\"Acronym\"]==idx, \"Metric Full Name\"].values[0]\n",
    "        \n",
    "        corr_df = tmp[[idx, \"Metric Full Name\"]].rename({idx: \"Correlation Coefficient\"}, axis=1)\n",
    "        corr_df = corr_df[[\"Metric Full Name\", \"Correlation Coefficient\"]]\n",
    "        corr_df = corr_df.style.set_caption(\"Indices strongly correlated with: \" + current_full_name)\n",
    "        df_dict[current_full_name] = corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb90e73-1bd0-44ee-8bea-1f92f48500c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('correlated_indicators_after_detrending.xlsx') as writer:\n",
    "    for sheet_name, df in df_dict.items():\n",
    "        print(sheet_name)\n",
    "        df.to_excel(writer, sheet_name=sheet_name.replace(\":\",\"--\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5006e703-8c38-4133-8be8-4c1b83fbc4d9",
   "metadata": {},
   "source": [
    "## Cross-Correlation between Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d693a1d-f8ee-4512-a806-02087e770e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlation(x,y):\n",
    "    xbar = x - np.mean(x)\n",
    "    ybar = y - np.mean(y)\n",
    "\n",
    "    num = np.dot(xbar,ybar)\n",
    "    denom = np.sqrt(np.dot(xbar, xbar) * np.dot(ybar, ybar))\n",
    "\n",
    "    cross_corr = num/denom\n",
    "\n",
    "    return cross_corr\n",
    "\n",
    "def cross_correlation_matrix(df1, df2):\n",
    "    ccdf = pd.DataFrame(index = df1.columns, columns = df2.columns)\n",
    "    for ind1 in df1.columns:\n",
    "        for ind2 in df2.columns:\n",
    "            ccdf.loc[ind1, ind2] = cross_correlation(df1[ind1].values, df2[ind2].values)\n",
    "\n",
    "    return ccdf.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ba69d-d879-47e3-a138-1ce3886955cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correlations_vecs = dict()\n",
    "cross_correlations_mats = dict()\n",
    "\n",
    "for i, cap1 in enumerate(four_capitals):\n",
    "    for j, cap2 in enumerate(four_capitals):\n",
    "        if j<=i:\n",
    "            continue\n",
    "        else:\n",
    "            cc = cross_correlation_matrix(wise_capitals_ch_clean[cap1], wise_capitals_ch_clean[cap2])\n",
    "            cross_correlations_mats[f\"{cap1} vs {cap2}\"] = cc\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "            ax = axs[0]\n",
    "            sns.heatmap(cc, vmin=-1, vmax=1, ax=axs[0])\n",
    "            ax.set_xlabel(cap2 + \" Capital\", fontsize=8)\n",
    "            ax.set_ylabel(cap1 + \" Capital\", fontsize=8)\n",
    "\n",
    "            ax = axs[1]\n",
    "\n",
    "            cc_vec = np.abs(cc.values.flatten())\n",
    "            cross_correlations_vecs[f\"{cap1} vs {cap2}\"] = cc_vec\n",
    "            sns.histplot(cc_vec, bins=20, ax=axs[1])\n",
    "            ax.grid(True)\n",
    "            ax.axvline(x=np.mean(np.abs(cc.values.flatten())), ls=\"--\", c=\"r\")\n",
    "            ax.set_xlabel(\"abs(cross correlation)\")\n",
    "            fig.suptitle(f\"Cross correlation matrix between {cap1} and {cap2} capitals\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9920e-f453-48b8-b384-374aacb4d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(cross_correlations_vecs, orient='h', ax=ax)\n",
    "ax.set_xlabel(\"abs(cross correlation)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a83a65-9eb1-4f83-86a3-f84530442ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = dict()\n",
    "bottoms = dict()\n",
    "for cap_pair, df in cross_correlations_mats.items():\n",
    "    df = df.rename(idx_name_map, axis=1).rename(idx_name_map, axis=0)\n",
    "    df = df.melt(value_vars=df.columns, ignore_index=False).sort_values(by=\"value\", ascending=False)\n",
    "    df = df[df.index != df[\"Acronym\"]]\n",
    "    df.index.name=cap_pair.split()[0]\n",
    "    df = df.rename({\"Acronym\": cap_pair.split()[2]}, axis=1)\n",
    "    tops[cap_pair] = df.head()\n",
    "    bottoms[cap_pair] = df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737f0a7-66fe-4fe2-93cd-9b3c726e3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('top_5_crosscorr_across_capitals.xlsx') as writer:\n",
    "    for sheet_name, df in tops.items():\n",
    "        print(sheet_name)\n",
    "        df.to_excel(writer, sheet_name=sheet_name.replace(\":\",\"--\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b395c6c-f7ca-4c56-9897-534957402dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('bottom_5_crossanticorr_across_capitals.xlsx') as writer:\n",
    "    for sheet_name, df in bottoms.items():\n",
    "        print(sheet_name)\n",
    "        df.to_excel(writer, sheet_name=sheet_name.replace(\":\",\"--\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbce424-f7b5-458b-a637-d0f776ac4f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "wise_db[\"Metrics Info\"][\"Theme\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe5af2-c7df-43b4-856d-fabc676584ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals_mapping = {\"Human\": [\"Education\", \"Income\", \"Health\", \"Labour\", \"Subjective Wellbeing\", \"Human Capital\"],\n",
    "                    \"Social\": [\"Governance\", \"Safety\", \"Population\"],\n",
    "                    \"Natural\": [\"Biodiversity\", \"Climate Change\", \"Land\", \"Energy Resources\", \"Physical Capital\", \"Air Quality\", \"Water\"],\n",
    "                    \"Economic\": [\"Financial capital\", \"Financial Capital\", \"Consumption\", \"Knowledge Capital\"],\n",
    "                    \"Other\": ['Non-energy Resources']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d89834-ea88-4000-84cc-b4ccca5627ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(l) for k,l in capitals_mapping.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf3bf5-a283-4d46-9e9e-abe58eb29a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
